import os
import gradio as gr
import argparse
import torch
import time
import chromadb
from chromadb.config import Settings
from docagent.retrieval.embedding.gemini_embedding import VLLMQwenEmbedding
from docagent.retrieval.database.milvus_database import ChromaDatabase
from docagent.retrieval.retriever.simple_retriever import SimpleRetriever

# Define the core JS logic as a string (to be embedded in onclick)
# Note: This string itself should not contain the outer function definition or call parenthesis.
# We also need to be careful with quotes and newlines within this string.
js_onclick_logic = r"""
    console.log('Inline onclick logic started for author:', authorName);
    /* Helper function definition */
    function findInputElementByLabelText(labelText) {
        let labelSpan = Array.from(document.querySelectorAll('label span')).find(el => el.textContent.includes(labelText));
        if (labelSpan) {
            let container = labelSpan.closest('.gradio-textbox, .gradio-textarea, .gradio-dropdown, .block');
            if (container) {
                let inputElement = container.querySelector('textarea, input[type="text"], input[type="search"], select');
                let clearButton = container.querySelector('.clear-button, .clear');
                return { input: inputElement, clearBtn: clearButton, container: container };
            }
        }
        console.warn(`Could not find container or input for label: ${labelText}`);
        return { input: null, clearBtn: null, container: null };
    }
    /* Clear other fields */
    console.log('Clearing other fields...');
    let titleInfo = findInputElementByLabelText('è®ºæ–‡æ ‡é¢˜');
    if (titleInfo.input) { titleInfo.input.value = ''; titleInfo.input.dispatchEvent(new Event('input', { bubbles: true })); } else { console.warn('Title input not found'); }
    let abstractInfo = findInputElementByLabelText('è®ºæ–‡æ‘˜è¦');
    if (abstractInfo.input && abstractInfo.input.tagName === 'TEXTAREA') { abstractInfo.input.value = ''; abstractInfo.input.dispatchEvent(new Event('input', { bubbles: true })); } else { console.warn('Abstract textarea not found'); }
    let journalInfo = findInputElementByLabelText('ç›®æ ‡æœŸåˆŠ');
    if (journalInfo.clearBtn) { journalInfo.clearBtn.click(); } else if (journalInfo.input) { journalInfo.input.value = ''; journalInfo.input.dispatchEvent(new Event('change', { bubbles: true })); } else { console.warn('Journal dropdown not found'); }
    let minYearInfo = findInputElementByLabelText('èµ·å§‹å¹´ä»½');
    if (minYearInfo.clearBtn) { minYearInfo.clearBtn.click(); } else if (minYearInfo.input) { minYearInfo.input.value = ''; minYearInfo.input.dispatchEvent(new Event('change', { bubbles: true })); } else { console.warn('Min year dropdown not found'); }
    let maxYearInfo = findInputElementByLabelText('ç»“æŸå¹´ä»½');
    if (maxYearInfo.clearBtn) { maxYearInfo.clearBtn.click(); } else if (maxYearInfo.input) { maxYearInfo.input.value = ''; maxYearInfo.input.dispatchEvent(new Event('change', { bubbles: true })); } else { console.warn('Max year dropdown not found'); }
    console.log('Finished clearing fields.');
    /* Set Author and Trigger Search */
    let authorInfo = findInputElementByLabelText('ä½œè€…å§“å');
    if (!authorInfo.input) {
        console.error('Could not find the author input element.');
        alert('æ— æ³•æ‰¾åˆ°ä½œè€…è¾“å…¥æ¡†ï¼Œæ— æ³•è‡ªåŠ¨æœç´¢ã€‚è¯·æ‰‹åŠ¨å¤åˆ¶ä½œè€…åã€‚');
        return;
    }
    let searchButton = Array.from(document.querySelectorAll('button')).find(el => el.textContent.trim() === 'å¼€å§‹æ£€ç´¢');
    if (!searchButton) {
        console.error('Could not find the search button.');
        alert('æ— æ³•æ‰¾åˆ°æœç´¢æŒ‰é’®ï¼Œæ— æ³•è‡ªåŠ¨æœç´¢ã€‚');
        return;
    }
    console.log('Setting author input:', authorInfo.input);
    authorInfo.input.value = authorName;
    authorInfo.input.dispatchEvent(new Event('input', { bubbles: true }));
    console.log('Clicking search button:', searchButton);
    searchButton.click();
    console.log('Author set and search button clicked.');
"""

# æ„å»ºè¿‡æ»¤è¡¨è¾¾å¼å‡½æ•°
def build_filters(journal=None, min_year=None, max_year=None, author=None):
    """æ„å»ºé€‚ç”¨äº ChromaDB çš„è¿‡æ»¤è¡¨è¾¾å¼ (where document)"""
    # æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°ç°åœ¨è¿”å› ChromaDB çš„ where dictï¼Œè€Œä¸æ˜¯å­—ç¬¦ä¸²
    db_conditions = [] # ä½¿ç”¨åˆ—è¡¨å­˜å‚¨ AND æ¡ä»¶

    # Venue Filter ($eq)
    if journal and journal.strip():
        db_conditions.append({"venue": {"$eq": journal.strip()}})

    # Time Filter ($gte, $lte, $and)
    time_conditions = []
    if min_year and min_year != "":
        try:
            time_conditions.append({"published": {"$gte": int(min_year)}})
        except ValueError:
            print(f"âš ï¸ æ— æ•ˆçš„æœ€å°å¹´ä»½å€¼: {min_year}")
    if max_year and max_year != "":
        try:
            time_conditions.append({"published": {"$lte": int(max_year)}})
        except ValueError:
            print(f"âš ï¸ æ— æ•ˆçš„æœ€å¤§å¹´ä»½å€¼: {max_year}")

    if len(time_conditions) > 1:
        db_conditions.append({"$and": time_conditions})
    elif len(time_conditions) == 1:
        db_conditions.append(time_conditions[0])

    # Author Filter ($or across author1..authorN)
    if author and author.strip():
        # å‡è®¾ä½œè€…è¾“å…¥æ˜¯å•ä¸ªå§“åæˆ–é€—å·åˆ†éš”çš„å¤šä¸ªå§“å
        # è¿™é‡Œæˆ‘ä»¬å¤„ç†å•ä¸ªä½œè€…ç²¾ç¡®åŒ¹é…çš„æƒ…å†µï¼Œä¸milvus_database.pyä¸­çš„è§£æé€»è¾‘ç±»ä¼¼
        # å¦‚æœéœ€è¦æ”¯æŒUIè¾“å…¥å¤šä¸ªä½œè€…å¹¶è¿›è¡ŒOR/ANDç»„åˆï¼Œé€»è¾‘ä¼šæ›´å¤æ‚
        # å½“å‰ç®€åŒ–ä¸ºï¼šå¦‚æœè¾“å…¥äº†ä½œè€…åï¼Œåˆ™åœ¨ author1 åˆ° author50 ä¸­æŸ¥æ‰¾å®Œå…¨åŒ¹é…é¡¹
        author_name_to_match = author.strip() # ç›´æ¥ä½¿ç”¨è¾“å…¥æ¡†çš„å€¼
        author_or_conditions = []
        # ä» milvus_database.py å¯¼å…¥æˆ–é‡æ–°å®šä¹‰ MAX_AUTHORS_PER_PAPER
        # ä¸ºç®€å•èµ·è§ï¼Œç›´æ¥åœ¨è¿™é‡Œç”¨å­—é¢é‡ 50
        MAX_AUTHORS_PER_PAPER = 50
        for i in range(1, MAX_AUTHORS_PER_PAPER + 1):
            author_or_conditions.append({f"author{i}": {"$eq": author_name_to_match}})

        if author_or_conditions:
             # åªéœ€è¦ä¸€ä¸ª $or æ¡ä»¶æ¥åŒ…å«æ‰€æœ‰ authorN å­—æ®µçš„æ£€æŸ¥
            db_conditions.append({"$or": author_or_conditions})
        # æ³¨æ„ï¼šä¹‹å‰çš„ LIKE "%term%" é€»è¾‘å·²è¢«ç§»é™¤ï¼Œæ›¿æ¢ä¸ºç²¾ç¡®åŒ¹é… $eq

    # Combine all conditions with $and if multiple exist
    if len(db_conditions) > 1:
        final_where = {"$and": db_conditions}
    elif len(db_conditions) == 1:
        final_where = db_conditions[0]
    else:
        final_where = None # No conditions

    print(f"[Debug build_filters] Generated ChromaDB where: {final_where}")
    return final_where

# ç³»ç»Ÿåˆå§‹åŒ–å‡½æ•° - ç›´æ¥è¿æ¥åˆ°ç‰¹å®šé›†åˆ
def initialize_system():
    """ç³»ç»Ÿåˆå§‹åŒ–å‡½æ•°ï¼Œç›´æ¥è¿æ¥åˆ°papers0520é›†åˆ"""
    try:
        start_time = time.time()
        
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        tensor_parallel_size = 1
        print(f"â³ åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ (tensor_parallel_size={tensor_parallel_size})...")
        embedding = VLLMQwenEmbedding(tensor_parallel_size=tensor_parallel_size)
        print("âœ… åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

        # è®¾ç½®ChromaDBè¿æ¥æ–¹å¼
        db_path = "/home/dataset-assist-0/data/chromadb/"
        print(f"ğŸ’¾ è¿æ¥åˆ°æ•°æ®åº“: {db_path}")
        chroma_client = chromadb.PersistentClient(
            path=db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # è·å–é›†åˆ
        collection_name = "papers0520"
        print(f"ğŸ“„ ä½¿ç”¨é›†åˆ: {collection_name}")
        collection = chroma_client.get_collection(name=collection_name)
        
        # åˆ›å»ºæ•°æ®åº“å¯¹è±¡
        database = ChromaDatabase(collection_name=collection_name, dim=embedding.embedding_dim)
        # æ›¿æ¢é»˜è®¤å®¢æˆ·ç«¯
        database.client = chroma_client
        database.collection = collection
        
        doc_count = collection.count()
        print(f"ğŸ“Š é›†åˆ {collection_name} ä¸­åŒ…å« {doc_count} ç¯‡è®ºæ–‡")
        
        retriever = SimpleRetriever(embedding, database)
        print("âœ… æ•°æ®åº“å’Œæ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        print(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œç”¨æ—¶ {processing_time:.2f} ç§’")
        
        return retriever

    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

# æ ¸å¿ƒæ£€ç´¢å‡½æ•°
def search_papers(query_title, query_abstract, top_k=5, journal=None, min_year=None, max_year=None, author=None):
    """æ ¸å¿ƒæ£€ç´¢å‡½æ•°"""
    # Keep the comprehensive debug print statement
    print(f"[Debug Full Inputs] Received: title='{query_title}' ({type(query_title)}), "
          f"abstract='{query_abstract}' ({type(query_abstract)}), "
          f"top_k={top_k} ({type(top_k)}), journal='{journal}' ({type(journal)}), "
          f"min_year='{min_year}' ({type(min_year)}), max_year='{max_year}' ({type(max_year)}), "
          f"author='{author}' ({type(author)})")

    # Restore the original validation and processing logic
    title_present = query_title and query_title.strip()
    abstract_present = query_abstract and query_abstract.strip()
    author_present = author and author.strip()

    if not (title_present or abstract_present or author_present):
        print("[Debug Full Inputs] Validation failed: No non-empty title, abstract, or author provided.")
        return "<div class='output-container'><div style='text-align:center;color:#666;'>âš ï¸ è¯·è‡³å°‘è¾“å…¥æ ‡é¢˜ã€æ‘˜è¦æˆ–ä½œè€…åç§°ï¼ˆä¸”ä¸ä¸ºç©ºï¼‰</div></div>"

    # Restore query_text building logic
    query_parts = []
    if title_present:
        query_parts.append(f"Title: {query_title}")
    if abstract_present:
        query_parts.append(f"Abstract: {query_abstract}")

    query_text = "\n".join(query_parts)
    # If only author is present, query_text will be empty.
    # Pass the author name as query_text if title/abstract are empty
    # to satisfy retriever's need for non-empty text for embedding.
    if not query_text and author_present:
        query_text = author
    # Handle the case where all inputs are empty (though validation should prevent this)
    if not query_text:
        # Provide a default or generic query string if absolutely necessary
        # Or rely on the retriever to handle this case if it can.
        # For now, we might let it proceed and potentially fail at the retriever if it requires text.
        # Alternatively, return an error earlier if query_text is mandatory for the retriever.
        print("Warning: query_text is empty after processing inputs. Proceeding...")
        # query_text = "general search" # Example placeholder if needed

    # Restore filter building and retrieval logic
    where_document = build_filters(journal, min_year, max_year, author)
    try:
        print(f"[Debug Full Inputs] Calling retriever.retrieve with query_text='{query_text}', top_k={top_k}, where_document={where_document}")
        # Ensure retriever is accessible (assuming it's initialized globally)
        results = retriever.retrieve(query_text=query_text, top_k=top_k, filter_expression=where_document)
    except Exception as e:
        print(f"âŒ Retriever Error: {e}")
        import traceback
        traceback.print_exc()
        return f"<div class='output-container'><div style='text-align:center;color:#666;'>âŒ æ£€ç´¢å¤±è´¥: {str(e)}</div></div>"

    if not results:
        return "<div class='output-container'><div style='text-align:center;color:#666;'>ğŸ” æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡</div></div>"

    # --- Add Deduplication Logic --- 
    print(f"[Debug] Results before deduplication: {len(results)} items")
    unique_results = []
    seen_titles = set()
    for paper in results:
        entity = paper.get('entity', {})
        title = entity.get('title')
        if title and title not in seen_titles:
            unique_results.append(paper)
            seen_titles.add(title)
    print(f"[Debug] Results after deduplication: {len(unique_results)} items")
    # Use unique_results for display, potentially limiting to top_k again if needed,
    # although the retriever might have already limited based on initial similarity.
    # If we want exactly top_k unique results, we might need to fetch more initially.
    # For now, display all unique results found within the initial fetch.
    display_results = unique_results 
    # --- End Deduplication Logic ---

    # å¼€å§‹æ„å»º HTML è¾“å‡º (use display_results instead of results)
    html_output = ["<div class='output-container'>"]
    for idx, paper in enumerate(display_results, 1):
        entity = paper.get('entity', {})
        summary = entity.get('summary', '')
        link = entity.get('link', 'æ— é“¾æ¥')
        title = entity.get('title', 'æœªçŸ¥')
        authors_raw = entity.get('authors', '') # Get raw authors string/list
        venue = entity.get('venue', 'æœªçŸ¥')
        published_year = entity.get('published', 'æœªçŸ¥')

        # Process authors for clickable links using inline JS
        authors_html = []
        if isinstance(authors_raw, str):
            authors_list = [a.strip() for a in authors_raw.split(',') if a.strip()]
        elif isinstance(authors_raw, list):
            authors_list = authors_raw # Assume it's already a list of strings
        else:
            authors_list = ['æœªçŸ¥']

        for author_name in authors_list:
            # Escape quotes for JS string literal and also for HTML attribute value
            js_escaped_author_name = author_name.replace("\\", "\\\\").replace("'", "\\'").replace('"', '&quot;')
            # Escape quotes for the HTML attribute value itself
            html_escaped_js_logic = js_onclick_logic.replace('"', '&quot;').replace("\n", " ") # Replace newlines for HTML attribute
            
            # Construct the onclick attribute with an IIFE embedding the logic
            onclick_attr = f"(function(authorName) {{{html_escaped_js_logic}}})(\'{js_escaped_author_name}\')"
            
            authors_html.append(f'<span class="author-link" onclick="{onclick_attr}">{author_name}</span>')

        authors_display_html = ", ".join(authors_html)

        html_output.append(f"""
            <div class="paper-result">
                <h3>åŒ¹é…ç»“æœ #{idx}</h3>
                <p><strong>ğŸ“– æ ‡é¢˜:</strong> {title}</p>
                <p><strong>ğŸ“„ æ‘˜è¦:</strong> {summary}</p>
                <p><strong>ğŸ‘¥ ä½œè€…:</strong> {authors_display_html}</p>
                <p><strong>ğŸ“° æœŸåˆŠ:</strong> {venue}</p>
                <p><strong>ğŸ“… å¹´ä»½:</strong> {published_year}</p>
                <p><strong>ğŸ”— é“¾æ¥:</strong> <a href="{link}" target="_blank">{link}</a></p>
            </div>
            """)
    html_output.append("</div>")
    return "".join(html_output)

# ç»Ÿè®¡å‡½æ•°
def analyze_authors_publications(keyword1, keyword2, keyword3, keyword4, keyword5, keyword6, min_year=None, max_year=None):
    """ç»Ÿè®¡ä½œè€…åœ¨ç‰¹å®šé¢†åŸŸçš„è®ºæ–‡å‘è¡¨æ•°é‡"""
    try:
        # å°†æ‰€æœ‰å…³é”®è¯æ”¾å…¥åˆ—è¡¨å¹¶æ¸…ç†
        keywords_list = [keyword1, keyword2, keyword3, keyword4, keyword5, keyword6]
        keywords = [kw.strip() for kw in keywords_list if kw.strip()]
        if not keywords:
            return "<div class='output-container'><div style='text-align:center;color:var(--text-color);'>âš ï¸ è¯·è‡³å°‘è¾“å…¥ä¸€ä¸ªå…³é”®è¯</div></div>"
            
        # å­˜å‚¨æ‰€æœ‰æ£€ç´¢åˆ°çš„è®ºæ–‡ï¼Œä½¿ç”¨å­—å…¸å­˜å‚¨å®Œæ•´è®ºæ–‡ä¿¡æ¯
        papers_dict = {}
        
        # æ„å»ºåŸºç¡€è¿‡æ»¤æ¡ä»¶
        filter_expr = build_filters(min_year=min_year, max_year=max_year)
        # ç§»é™¤æ’é™¤ç‰¹å®šæœŸåˆŠçš„æ¡ä»¶
        # if filter_expr:
        #     filter_expr += ' AND venue != "nature"'
        # else:
        #     filter_expr = 'venue != "nature"'
            
        # å¯¹æ¯ä¸ªå…³é”®è¯è¿›è¡Œæ£€ç´¢
        for keyword in keywords:
            try:
                results = retriever.retrieve(query_text=keyword, top_k=200, filter_expression=filter_expr)
                # å­˜å‚¨å®Œæ•´çš„è®ºæ–‡ä¿¡æ¯
                for paper in results:
                    title = paper['entity']['title']
                    if title not in papers_dict:  # é¿å…é‡å¤æ·»åŠ 
                        papers_dict[title] = paper['entity']
            except Exception as e:
                print(f"æ£€ç´¢å…³é”®è¯ '{keyword}' æ—¶å‡ºé”™: {str(e)}")
                continue
                
        if not papers_dict:
            return "<div class='output-container'><div style='text-align:center;color:var(--text-color);'>ğŸ” æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡</div></div>"
        
        # ç»Ÿè®¡ä½œè€…å‘è¡¨æ•°é‡
        author_stats = {}
        # ç›´æ¥ä½¿ç”¨å­˜å‚¨çš„è®ºæ–‡ä¿¡æ¯è¿›è¡Œç»Ÿè®¡
        for paper in papers_dict.values():
            authors = paper['authors'].split(", ")
            for author in authors:
                author = author.strip()
                if author:
                    author_stats[author] = author_stats.get(author, 0) + 1
        
        # æ’åºä½œè€…æŒ‰è®ºæ–‡æ•°é‡
        sorted_authors = sorted(author_stats.items(), key=lambda x: x[1], reverse=True)
        
        # æ„å»ºHTMLè¾“å‡º
        html_output = ["<div class='output-container'>"]
        html_output.append(f"<h2>ç ”ç©¶é¢†åŸŸä½œè€…è®ºæ–‡å‘è¡¨ç»Ÿè®¡</h2>")
        html_output.append(f"<p>æ£€ç´¢å…³é”®è¯: {', '.join(keywords)}</p>")
        html_output.append(f"<p>æ€»å…±æ‰¾åˆ°ç›¸å…³è®ºæ–‡: {len(papers_dict)} ç¯‡</p>")
        html_output.append("<div class='stats-container'>")
        
        for idx, (author, count) in enumerate(sorted_authors[:30], 1):  # æ˜¾ç¤ºå‰30å
            html_output.append(f"""
                <div class="author-stat-card">
                    <h3>#{idx} {author}</h3>
                    <p class="paper-count">å‘è¡¨è®ºæ–‡æ•°ï¼š{count}</p>
                </div>
            """)
        
        html_output.append("</div></div>")
        return "".join(html_output)
    
    except Exception as e:
        return f"<div class='output-container'><div style='text-align:center;color:var(--text-color);'>âŒ ç»Ÿè®¡å¤±è´¥: {str(e)}</div></div>"

# CSSæ ·å¼
css = """
/* æš—è‰²æ¨¡å¼æ£€æµ‹ */
:root {
    --background-color: #ffffff;
    --text-color: #666666;
    --card-background: #f8f9fa;
    --card-border: #e9ecef;
    --primary-color: #2196f3;
    --primary-hover: #1976d2;
    --title-color: #2c3e50;
    --input-border: #e0e0e0;
    --input-background: #ffffff;
    --container-background: #ffffff;
    --container-shadow: rgba(0,0,0,0.1);
    --group-background: #f8f9fa;
}

@media (prefers-color-scheme: dark) {
    :root {
        --background-color: #1e1e1e;
        --text-color: #cccccc;
        --card-background: #2d2d2d;
        --card-border: #3d3d3d;
        --primary-color: #0e88e8;
        --primary-hover: #0a6eb9;
        --title-color: #e0e0e0;
        --input-border: #555555;
        --input-background: #3d3d3d;
        --container-background: #2d2d2d;
        --container-shadow: rgba(0,0,0,0.3);
        --group-background: #333333;
    }
}

/* å…¨å±€æ ·å¼ */
body, .gradio-container { /* Apply font globally */
    font-family: 'Microsoft YaHei', 'å¾®è½¯é›…é»‘', sans-serif !important;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
}

/* æ ‡é¢˜æ ·å¼ */
h1, h2, h3, h4, h5, h6 {
    font-family: "Microsoft YaHei", "å¾®è½¯é›…é»‘", sans-serif !important;
}

h1 {
    text-align: center;
    color: var(--title-color);
    padding: 20px 0;
    margin-bottom: 30px;
    border-bottom: 2px solid var(--card-border);
}

/* è¾“å…¥é¢æ¿æ ·å¼ */
.input-container {
    background: var(--container-background);
    border-radius: 10px;
    padding: 20px;
    box-shadow: 0 2px 6px var(--container-shadow);
    margin-bottom: 20px;
}

/* è¾“å…¥æ¡†æ ·å¼ */
.gr-textbox, .gr-textarea {
    border: 1px solid var(--input-border) !important;
    border-radius: 8px !important;
    padding: 10px !important;
    font-size: 14px !important;
    transition: all 0.3s ease;
    background-color: var(--input-background) !important;
    color: var(--text-color) !important;
}

.gr-textbox:focus, .gr-textarea:focus {
    border-color: var(--primary-color) !important;
    box-shadow: 0 0 0 2px rgba(33,150,243,0.1) !important;
}

/* æŒ‰é’®æ ·å¼ */
.gr-button {
    border-radius: 8px !important;
    padding: 10px 20px !important;
    font-weight: 600 !important;
    transition: all 0.3s ease !important;
    font-family: "Microsoft YaHei", "å¾®è½¯é›…é»‘", sans-serif !important;
}

.gr-button.primary {
    background: var(--primary-color) !important;
    border: none !important;
}

.gr-button.primary:hover {
    background: var(--primary-hover) !important;
    transform: translateY(-1px);
}

/* ç»“æœé¢æ¿æ ·å¼ */
.output-container {
    background: var(--container-background);
    border-radius: 10px;
    padding: 20px !important;
    height: 800px !important;
    overflow-y: auto;
    box-shadow: 0 2px 6px var(--container-shadow);
    color: var(--text-color);
}

.paper-result {
    background: var(--card-background);
    border-radius: 8px;
    padding: 15px !important;
    margin: 15px 0 !important;
    border: 1px solid var(--card-border);
    transition: all 0.3s ease;
}

.paper-result:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 8px var(--container-shadow);
}

.paper-result h3 {
    color: var(--primary-color);
    margin: 0 0 15px 0 !important;
    font-size: 18px !important;
}

.paper-result p {
    margin: 8px 0 !important;
    line-height: 1.5;
}

.paper-result a {
    color: var(--primary-color);
}

/* åˆ†ç»„æ ·å¼ */
.search-group {
    background: var(--group-background);
    border-radius: 8px;
    padding: 15px;
    margin-bottom: 15px;
}

.search-group-title {
    font-size: 16px;
    font-weight: 600;
    margin-bottom: 15px;
    color: var(--title-color);
}

/* ç»Ÿè®¡ç»“æœæ ·å¼ */
.stats-container {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
    gap: 15px;
    padding: 15px;
}

.author-stat-card {
    background: var(--container-background);
    border-radius: 8px;
    padding: 15px;
    box-shadow: 0 2px 4px var(--container-shadow);
    transition: all 0.3s ease;
}

.author-stat-card:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 8px rgba(0,0,0,0.2);
}

.author-stat-card h3 {
    color: var(--primary-color);
    margin: 0 0 10px 0;
    font-size: 16px;
}

.paper-count {
    font-size: 14px;
    color: var(--text-color);
    margin: 0;
}

/* æ ‡ç­¾é¡µæ ·å¼ */
.tab-selected {
    background: var(--primary-color) !important;
    color: white !important;
}

/* Style for clickable authors */
.author-link {
    color: var(--primary-color); /* Use primary color for link */
    text-decoration: underline;
    cursor: pointer;
    margin-right: 5px; /* Add some spacing between names */
}
.author-link:hover {
    color: var(--link-hover-color); /* Define a hover color if needed */
}

"""

# ç¤ºä¾‹æœŸåˆŠå’Œå¹´ä»½åˆ—è¡¨ - ç§»åˆ°è¿™é‡Œï¼Œç¡®ä¿åœ¨æ„å»ºç•Œé¢å‰å®šä¹‰
journal_list = ["nature", "science", "cell"]
year_list = [str(year) for year in range(2025, 1899, -1)]

# æ›´æ–°Gradioç•Œé¢
with gr.Blocks(title="AI4så­¦æœ¯è®ºæ–‡æ™ºèƒ½æ£€ç´¢å¹³å°", theme=gr.themes.Soft(), css=css) as interface:
    gr.Markdown("""
        # ğŸ“š AI4så­¦æœ¯è®ºæ–‡æ™ºèƒ½æ£€ç´¢å¹³å°
        ### æ™ºèƒ½æ£€ç´¢æ‚¨éœ€è¦çš„å­¦æœ¯è®ºæ–‡
    """)
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    with gr.Tabs():
        # è®ºæ–‡æ£€ç´¢æ ‡ç­¾é¡µ
        with gr.Tab("è®ºæ–‡æ£€ç´¢"):
            with gr.Row(equal_height=True):
                # å·¦ä¾§è¾“å…¥é¢æ¿
                with gr.Column(scale=1, min_width=300):
                    with gr.Column(elem_classes="input-container"):
                        # Restore title and abstract inputs
                        with gr.Column(elem_classes="search-group"):
                            gr.Markdown("### ğŸ“ åŸºç¡€æœç´¢", elem_classes="search-group-title")
                            title_input = gr.Textbox(
                                label="è®ºæ–‡æ ‡é¢˜",
                                placeholder="è¾“å…¥è®ºæ–‡æ ‡é¢˜ï¼ˆé€‰å¡«ï¼‰...",
                            )
                            abstract_input = gr.TextArea(
                                label="è®ºæ–‡æ‘˜è¦",
                                placeholder="è¾“å…¥è®ºæ–‡æ‘˜è¦ï¼ˆé€‰å¡«ï¼‰...",
                                lines=4,
                            )
                        
                        with gr.Accordion("ğŸ” é«˜çº§ç­›é€‰", open=True):
                            with gr.Column(elem_classes="search-group"):
                                # Ensure author_input is defined here (or moved from base search if duplicated)
                                author_input = gr.Textbox(
                                    label="ä½œè€…å§“å",
                                    placeholder="è¾“å…¥å®Œæ•´çš„ä½œè€…å§“åï¼ˆç²¾ç¡®åŒ¹é…ï¼‰...",
                                )
                                journal_input = gr.Textbox(
                                    label="ç›®æ ‡æœŸåˆŠ",
                                    placeholder="è¾“å…¥æœŸåˆŠåç§°ï¼ˆé€‰å¡«ï¼‰...",
                                )
                                with gr.Row():
                                    min_year_input = gr.Dropdown(
                                        label="èµ·å§‹å¹´ä»½",
                                        choices=year_list,
                                        value=None
                                    )
                                    max_year_input = gr.Dropdown(
                                        label="ç»“æŸå¹´ä»½",
                                        choices=year_list,
                                        value=None
                                    )
                        
                        with gr.Row():
                            top_k_input = gr.Slider(
                                minimum=1,
                                maximum=30,
                                value=5,
                                step=1,
                                label="æ˜¾ç¤ºè®ºæ–‡æ•°é‡"
                            )
                            search_btn = gr.Button(
                                "å¼€å§‹æ£€ç´¢",
                                variant="primary",
                                scale=1
                            )

                # å³ä¾§ç»“æœé¢æ¿
                with gr.Column(scale=2):
                    output_panel = gr.HTML(
                        value="<div class='output-container'><div style='text-align:center;color:var(--text-color);padding:20px;'>ç­‰å¾…æ£€ç´¢ï¼Œè¯·è¾“å…¥æœç´¢æ¡ä»¶...</div></div>"
                    )

        # ä½œè€…ç»Ÿè®¡æ ‡ç­¾é¡µ
        with gr.Tab("ä½œè€…ç»Ÿè®¡"):
            with gr.Column():
                with gr.Column(elem_classes="input-container"):
                    # ä¿®æ”¹ä¸º6ä¸ªå…³é”®è¯è¾“å…¥æ¡†
                    keywords_inputs = []
                    for i in range(6):
                        keywords_inputs.append(
                            gr.Textbox(
                                label=f"ç ”ç©¶é¢†åŸŸå…³é”®è¯ {i+1}",
                                placeholder=f"è¾“å…¥ç¬¬{i+1}ä¸ªç ”ç©¶é¢†åŸŸå…³é”®è¯...",
                                value="" if i > 0 else "ai for science"
                            )
                        )
                    with gr.Row():
                        stat_min_year = gr.Dropdown(
                            label="èµ·å§‹å¹´ä»½",
                            choices=year_list,
                            value=None
                        )
                        stat_max_year = gr.Dropdown(
                            label="ç»“æŸå¹´ä»½",
                            choices=year_list,
                            value=None
                        )
                    analyze_btn = gr.Button("å¼€å§‹ç»Ÿè®¡", variant="primary")
                
                stats_output = gr.HTML(
                    value="<div class='output-container'><div style='text-align:center;color:var(--text-color);'>ç­‰å¾…ç»Ÿè®¡...</div></div>"
                )
    
    # äº‹ä»¶ç»‘å®š
    search_btn.click(
        fn=search_papers,
        inputs=[
            title_input,      # 1. query_title
            abstract_input,   # 2. query_abstract
            top_k_input,      # 3. top_k
            journal_input,    # 4. journal
            min_year_input,   # 5. min_year
            max_year_input,   # 6. max_year
            author_input      # 7. author
        ],
        outputs=output_panel
    )
    
    analyze_btn.click(
        fn=analyze_authors_publications,
        inputs=[*keywords_inputs, stat_min_year, stat_max_year],
        outputs=stats_output
    )

if __name__ == "__main__":
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="AI4så­¦æœ¯è®ºæ–‡æ™ºèƒ½æ£€ç´¢å¹³å°")
    parser.add_argument('--port', type=int, default=8081, help='æœåŠ¡ç«¯å£å·')
    parser.add_argument('--no-share', action='store_true', help='ä¸åˆ›å»ºå…¬å…±é“¾æ¥')
    args = parser.parse_args()
    
    # ç³»ç»Ÿåˆå§‹åŒ–
    print(f"ğŸš€ ç³»ç»Ÿå¯åŠ¨ - ç«¯å£: {args.port}")
    retriever = initialize_system()
    
    # å¯åŠ¨ç•Œé¢
    interface.launch(server_port=args.port, share=not args.no_share)