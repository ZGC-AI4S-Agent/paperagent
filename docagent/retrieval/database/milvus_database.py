# milvus_database.py
import chromadb
from chromadb.config import Settings
import os
import uuid  # æ·»åŠ uuidæ¨¡å—å¯¼å…¥
import re # éœ€è¦å¯¼å…¥ re æ¨¡å—

# Define the maximum number of author fields to store separately
MAX_AUTHORS_PER_PAPER = 50

class ChromaDatabase:
    def __init__(self, collection_name, dim):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        # è®¾ç½®å­˜å‚¨è·¯å¾„ - ä½¿ç”¨ç‰¹å®šå®ä¾‹ç›®å½•
        # å¯ä»¥é€‰æ‹©ä½¿ç”¨æ ¹ç›®å½•æˆ–ç‰¹å®šå®ä¾‹ç›®å½•
        persist_directory = "/home/dataset-assist-0/data/chromadb"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(persist_directory, exist_ok=True)
        
        # åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯
        self.client = chromadb.PersistentClient(
            path=persist_directory,
            settings=Settings(
                anonymized_telemetry=False
            )
        )
        
        self.collection_name = collection_name
        self.dim = dim
        
        # åˆ›å»ºæˆ–è·å–é›†åˆ
        # Check if the collection exists to potentially update metadata definition if needed
        # Although ChromaDB is flexible, explicitly defining metadata structure might be good practice
        # For now, we rely on dynamic schema
        try:
            self.collection = self.client.get_collection(name=collection_name)
            print(f"âœ… æˆåŠŸè·å–å·²å­˜åœ¨çš„é›†åˆ: {collection_name}")
        except Exception: # Handle cases where collection might not exist or other errors
             print(f"â„¹ï¸ é›†åˆ {collection_name} ä¸å­˜åœ¨æˆ–è·å–å¤±è´¥ï¼Œå°†åˆ›å»ºæ–°é›†åˆã€‚")
             # Ensure dimension is passed correctly if creating
             # Metadata for space/dimension is often set at creation, let's keep it
             collection_metadata = {"hnsw:space": "cosine"}
             # Note: ChromaDB schema can be dynamic, adding dimension here might be informational
             # collection_metadata["dimension"] = dim # Re-check if needed/supported here

             self.collection = self.client.get_or_create_collection(
                 name=collection_name,
                 metadata=collection_metadata
             )
             print(f"âœ… æˆåŠŸåˆ›å»ºæ–°é›†åˆ: {collection_name}")


        # è®°å½•é›†åˆå½“å‰æ–‡æ¡£æ•°ï¼Œç”¨äºç”Ÿæˆå”¯ä¸€ID
        self.doc_count = self.collection.count()
        print(f"å½“å‰é›†åˆä¸­å·²æœ‰æ–‡æ¡£æ•°: {self.doc_count}")

    def insert_documents(self, documents):
        """æ‰¹é‡æ’å…¥æ–‡æ¡£ï¼Œå¹¶å°†ä½œè€…æ‹†åˆ†åˆ°å•ç‹¬å­—æ®µ"""
        # å‡†å¤‡æ•°æ®
        ids = []
        documents_list = []
        embeddings = []
        metadatas = []

        for i, doc in enumerate(documents):
            unique_id = f"doc_{self.doc_count + i}"
            ids.append(unique_id)
            documents_list.append(f"{doc['title']} {doc['summary']}") # Document content remains the same
            embeddings.append(doc['vector'])

            # Prepare metadata, including split authors
            metadata = {
                "title": doc["title"],
                "summary": doc["summary"],
                "authors": doc["authors"], # Keep the original string/list for display
                "venue": doc["venue"],
                "link": doc.get("link", ""), # <-- Use 'link' from source, store as 'link'
                "published": doc["published"]
            }

            # Split authors and add author1, author2, ... fields
            authors_list = []
            if isinstance(doc["authors"], list):
                 authors_list = doc["authors"]
            elif isinstance(doc["authors"], str):
                 # Simple split, adjust if delimiter is different or needs trimming
                 authors_list = [a.strip() for a in doc["authors"].split(',') if a.strip()]

            for j in range(MAX_AUTHORS_PER_PAPER):
                author_field_name = f"author{j+1}"
                if j < len(authors_list):
                    metadata[author_field_name] = authors_list[j]
                else:
                    # Set remaining author fields to a default value (e.g., empty string or None)
                    # Using empty string might be safer for filtering ($eq: "")
                    metadata[author_field_name] = ""

            metadatas.append(metadata)

        # æ‰¹é‡æ’å…¥
        try:
            self.collection.add(
                ids=ids,
                documents=documents_list, # Content for vector search
                embeddings=embeddings,
                metadatas=metadatas # Metadata including author1..N
            )
            self.doc_count += len(documents)
            print(f"âœ… æˆåŠŸæ’å…¥ {len(documents)} æ¡æ•°æ® (å«æ‹†åˆ†ä½œè€…å­—æ®µ)ï¼Œå½“å‰æ€»æ•°: {self.doc_count}")
        except Exception as e:
            print(f"âŒ æ•°æ®æ’å…¥å¤±è´¥: {str(e)}")
            # Consider logging the problematic batch/metadata for debugging
            # import traceback
            # traceback.print_exc()


    def similarity_search(self, query_vector, top_k=5, filter_expression=None):
        """ç›¸ä¼¼æ€§æœç´¢ï¼Œç›´æ¥ä½¿ç”¨ä¼ å…¥çš„ filter_expression ä½œä¸º where æ¡ä»¶ã€‚"""
        # æ³¨æ„ï¼šfilter_expression ç°åœ¨åº”è¯¥æ˜¯ä¸€ä¸ª ChromaDB where document (å­—å…¸)
        # ç§»é™¤äº†ä¹‹å‰çš„å­—ç¬¦ä¸²è§£æé€»è¾‘
        where_conditions = filter_expression # Directly use the dictionary

        # æ·»åŠ è°ƒè¯•æ‰“å°ï¼Œç¡®è®¤ä¼ å…¥çš„æ¡ä»¶
        print(f"[Debug DB] Received where_conditions for query: {where_conditions}")

        try:
            # Execute DB search with the provided where clause
            print(f"ğŸ” æ‰§è¡Œ ChromaDB æŸ¥è¯¢ï¼ŒTop K: {top_k}, DB Where: {where_conditions}")
            results = self.collection.query(
                query_embeddings=[query_vector] if query_vector else None,
                n_results=top_k,
                where=where_conditions, # Use the received dictionary directly
                include=["metadatas", "distances"]
            )

            # Format results (no client-side filtering needed now)
            formatted_results = []
            if results and results["ids"] and results["ids"][0]:
                for i in range(len(results["ids"][0])):
                    if results["metadatas"] and len(results["metadatas"]) > 0 and results["metadatas"][0] and len(results["metadatas"][0]) > i:
                        metadata = results["metadatas"][0][i]
                        # Remove author1..N fields before returning to keep API clean? Optional.
                        # entity = {k: v for k, v in metadata.items() if not k.startswith('author')}
                        entity = metadata # Keep all metadata for now

                        formatted_results.append({
                            "entity": entity,
                             # Handle case where distances might be None if query_embeddings wasn't provided/used effectively
                            "distance": results["distances"][0][i] if results["distances"] and results["distances"][0] else None
                        })
                    else:
                        print(f"âš ï¸ è­¦å‘Šï¼šæŸ¥è¯¢ç»“æœä¸­ç¼ºå°‘ç´¢å¼• {i} çš„å…ƒæ•°æ®ã€‚")
            else:
                 print("â„¹ï¸ ChromaDB æŸ¥è¯¢æœªè¿”å›ä»»ä½•ç»“æœã€‚")


            return formatted_results

        except Exception as e:
            print(f"âŒ ChromaDB æœç´¢å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []